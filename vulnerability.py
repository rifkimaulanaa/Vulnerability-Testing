import re
from urllib.parse import urljoin, urlparse, parse_qs, quote
from urllib.request import urlopen
from urllib.error import URLError, HTTPError
import html.parser
import random
import string
from collections import defaultdict
import chardet
import logging


# Konfigurasi logging
logging.basicConfig(filename='scan_log.txt', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def scan_website(url, max_depth=2):
    discovered_urls = discover_urls(url)
    visited_urls = set()

    for depth in range(max_depth + 1):
        for page_url in list(discovered_urls):
            if page_url not in visited_urls:
                vulnerabilities = scan_url(page_url)
                if vulnerabilities:
                    print(f"\nKerentanan ditemukan pada {page_url}:")
                    for vuln, attacks in vulnerabilities.items():
                        print(f"- {vuln}:")
                        for attack in attacks:
                            print(f"  - {attack}")

                visited_urls.add(page_url)
                new_urls = discover_urls(page_url)
                discovered_urls.update(new_urls - visited_urls)

class MyHTMLParser(html.parser.HTMLParser):
    def __init__(self):
        super().__init__()
        self.links = []

    def handle_starttag(self, tag, attrs):
        if tag == "a":
            for attr in attrs:
                if attr[0] == "href":
                    self.links.append(attr[1])

def discover_urls(url):
    discovered_urls = set()
    try:
        response = urlopen(url)
        if response.getcode() == 200:
            content = response.read()
            detected_encoding = chardet.detect(content)
            encoding = detected_encoding['encoding'] if detected_encoding['encoding'] is not None else 'utf-8'
            parser = MyHTMLParser()
            parser.feed(content.decode(encoding, errors='replace')) # decode di sini

            for href in parser.links:
                if href and not href.startswith("#"):
                    absolute_url = urljoin(url, href)
                    discovered_urls.add(absolute_url)

            # Ekstrak parameter dan nilai input
            parsed_url = urlparse(url)
            query_params = parse_qs(parsed_url.query)
            if query_params:  # Periksa apakah query_params adalah dictionary
                for param, values in query_params.items():
                    for value in values:
                        fuzzed_values = fuzz_input(value)
                        for fuzzed_value in fuzzed_values:
                            new_query = parsed_url.query.replace(value, fuzzed_value)
                            new_url = urljoin(url, f"{parsed_url.path}?{new_query}")
                            discovered_urls.add(new_url)
        else:
            logging.warning(f"Gagal mengambil {url}: Kode Status {response.getcode()}")

    except URLError as e:
        logging.error(f"Gagal mengambil {url}: {e}")
    except Exception as e:  # Tangani pengecualian umum lainnya
        logging.error(f"Terjadi kesalahan saat mengambil {url}: {e}")

    return discovered_urls


def scan_url(url):
    vulnerabilities = defaultdict(list)

    if is_sql_injection_vulnerable(url):
        vulnerabilities["SQL Injection"].append("Memasukkan kode SQL ke dalam kolom input")

    if is_xss_vulnerable(url):
        vulnerabilities["Cross-Site Scripting (XSS)"].append("Menyuntikkan skrip berbahaya ke dalam kolom input")

    if is_lfi_vulnerable(url):
        vulnerabilities["Local File Inclusion (LFI)"].append("Mencoba membaca file lokal melalui input")

    if is_command_injection_vulnerable(url):
        vulnerabilities["Command Injection"].append("Menjalankan perintah sistem melalui input")

    if is_open_redirection_vulnerable(url):
        vulnerabilities["Open Redirection"].append("Mengarahkan pengguna ke URL lain melalui input")

    # Implementasi is_idor_vulnerable dan is_csrf_vulnerable memerlukan analisis kode lebih lanjut

    return vulnerabilities

# ... (fungsi is_sql_injection_vulnerable, is_xss_vulnerable, is_lfi_vulnerable, is_command_injection_vulnerable, is_open_redirection_vulnerable)

def is_sql_injection_vulnerable(url):
    payload = "' OR '1'='1"
    encoded_payload = quote(payload)
    try:
        response = urlopen(url + "?id=" + encoded_payload)
        content = response.read()
        detected_encoding = chardet.detect(content)
        encoding = detected_encoding['encoding'] if detected_encoding['encoding'] is not None else 'utf-8'
        decoded_content = content.decode(encoding, errors='replace')
        if re.search(r"error|warning", decoded_content, re.IGNORECASE):
            return True
    except URLError:
        pass
    return False

def is_xss_vulnerable(url):
    payload = "<script>alert('XSS')</script>"
    encoded_payload = quote(payload)
    try:
        response = urlopen(url + "?input=" + encoded_payload)
        content = response.read()
        detected_encoding = chardet.detect(content)
        encoding = detected_encoding['encoding'] if detected_encoding['encoding'] is not None else 'utf-8'
        decoded_content = content.decode(encoding, errors='replace')
        if payload in decoded_content:
            return True
    except URLError:
        pass
    return False

def is_lfi_vulnerable(url):
    payloads = ["/etc/passwd", "../../etc/passwd"]
    for payload in payloads:
        encoded_payload = quote(payload)
        try:
            response = urlopen(url + "?file=" + encoded_payload)
            content = response.read()
            detected_encoding = chardet.detect(content)
            encoding = detected_encoding['encoding'] if detected_encoding['encoding'] is not None else 'utf-8'
            decoded_content = content.decode(encoding, errors='replace')
            if "root:" in decoded_content:
                return True
        except URLError:
            pass
    return False

def is_command_injection_vulnerable(url):
    payload = "; cat /etc/passwd"
    encoded_payload = quote(payload)
    try:
        response = urlopen(url + "?cmd=" + encoded_payload)
        content = response.read()
        detected_encoding = chardet.detect(content)
        encoding = detected_encoding['encoding'] if detected_encoding['encoding'] is not None else 'utf-8'
        decoded_content = content.decode(encoding, errors='replace')
        if "root:" in decoded_content:
            return True
    except URLError:
        pass
    return False

def is_open_redirection_vulnerable(url):
    payload = "https://www.google.com"
    try:
        response = urlopen(url + "?redirect=" + payload)
        if response.geturl() == payload:
            return True
    except URLError:
        pass
    return False



def fuzz_input(input_value):
    fuzzed_values = []

    # Fuzzing string
    fuzzed_values.append(input_value + "'")
    fuzzed_values.append(input_value + "<script>alert('XSS')</script>")

    # Fuzzing angka
    if input_value.isdigit():
        fuzzed_values.append(str(int(input_value) + 1))
        fuzzed_values.append(str(int(input_value) - 1))

    return fuzzed_values

# Input Pengguna
target_url = input("Masukkan URL target: ")
max_depth = int(input("Masukkan kedalaman crawling (0 untuk tidak crawling): "))

# Pemindaian
scan_website(target_url, max_depth)


# Di Buat Oleh
name = "Rifki Maulana"
title = "Cyber Security Analyst"

print("\n")
print("#############################################")
print(f"Script by: {name}")
print(f"Title: {title}")
print("#############################################")
